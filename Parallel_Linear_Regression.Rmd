---
title: "Parallel Linear Regression"
author: "ynakahashi"
date: "2018/6/28"
output: html_document
---


## データを小集団に分割しながら線形回帰の解を推定する

[contents:]


### 背景
突然ですが、一般に線形回帰と言えば以下の正規方程式：

[tex: X'Xb = (X'X)\^{-1}X'y]

をbについて解くことで得られると教わり、そのまま理解していることが多いのではないでしょうか。

これ自体は決して間違っていないのですが、実装においては計算精度の問題から、逆行列ではなくQR分解を活用して解いている場合があります。例えばRでも、以前の記事において`lm`のソースコードをたどっていった結果、ハウスホルダー変換によってQR分解が行われていることを確認しました。

以前の記事はこちら。

ここで`lm`と逆行列およびQR分解による解の推定値をちょっと見てみましょう。適当にデータを作成します。

```{r}
set.seed(123)
n <- 100
b <- c(1, 1.5) # 切片と回帰係数
x <- cbind(1, rnorm(n))
y <- x %*% b + rnorm(n)
```

また、それぞれによる解の推定方法を以下のように定義します。

```{r}
## lm(.fit)を使う
my_lm <- function() { coef(lm.fit(x, y)) }

## 逆行列で解く
my_solve <- function() { solve(crossprod(x, x)) %*% crossprod(x, y) }

## QR分解で解く
my_qr <- function() { solve(qr.R(qr(x))) %*% t(qr.Q(qr(x))) %*% y }
```

上で定義した関数は、いずれも同じ解を返します：

```{r}
cbind(my_solve(), my_qr(), my_lm())
```

一緒の値になっていますね。少し脱線しますが、ついでに計算時間も見てみましょう：

```{r}
time_1000 <- data.frame(microbenchmark::microbenchmark(my_solve(), my_qr(), my_lm(), times = 1000))

library(ggplot2)
ggplot(time_1000, aes(x = expr, y = log(time), group = expr)) +
   geom_violin() + 
   coord_flip() +
   labs(x = "functions") +
   NULL
```

逆行列を用いた場合が一番早く、QR分解を用いたものが最も遅いようでした。なおこのグラフは横軸が対数となっていることに注意してください。

さて、このようにして線形回帰の解はQR分解を使って求めることができますが、実は計算を工夫することで、Xを小集団に分割した上でそれぞれのデータからX全体の解を得ることができます。これが何を意味するかというと、メモリに全部載せきれないような大きいデータであっても解を推定したり、あるいは線形回帰であっても並列に計算を回すことができる、ということです[^1]。

もともと今回の記事を書こうと思ったのは、以前に「線形回帰はデータを分割して並列計算できる」という話を知人から聞いたことをふと思い出したのがきっかけです。当時は何を言っているのか今いち理解できなかったのですが、大変わかりやすい下記の記事を見つけたため、写経した内容をメモしておきます。

[https://freakonometrics.hypotheses.org/53269:cited]

[^1]:果たして今の時代にどれほどのニーズがあるのかわかりませんが。。。

### 手順
実装に取り掛かる前に手順について簡単に理解しておきましょう。まずXをQR分解すると、冒頭に示した正規方程式から得られる[tex: \hat{\beta}]は以下のようになります：

$$
X = QR \\
\hat{\beta} = (X'X)^{-1}X'y = (R'Q'QR)^{-1}R'Q'y = (R'R)^{-1}R'Q'y
$$

QR分解によって得られる行列Qは直交行列であるため、[tex: (Q'Q) = I]となります。またここで積の逆行列は[tex: (AB)^{-1} = B^{-1}A^{-1}]という性質があることから、

$$
(R'R)^{-1}R'Q'y = R^{-1}R'^{-1}R'Q'y = R^{-1}Q'y
$$

となります。すなわちQR分解によって得られた行列Rの逆行列と、行列Qの転置があれば良いことになります。先ほど`my_qr`を定義したときは説明なく示しましたが、これは下のように書けます：

```{r}
## my_qrの定義（再掲）
solve(qr.R(qr(x))) %*% t(qr.Q(qr(x))) %*% y
```

問題は、この[tex: R^{-1}]および[tex: Q']をどのようにして小集団から再構成するか、ということになりますが、これは以下の手順で計算できるようです：

1. 共通処理
   1. X、yをそれぞれ小集団に分割する
   2. 各小集団のXをQR分解する
2. [tex: R^{-1}]を計算する
   1. 各小集団からのRを統合する
   2. 再度QR分解してRを得る
   3. Rの逆行列[tex: R^{1}]を求める
3. [tex: Q']を計算する
   1. 1-2で得られたQを2-2で得たQに乗じる（[tex: Q']）
4. 2と3の結果およびyにより解を得る
   1. 3-1で得たQ'にyを乗じる
   2. 両者を乗じる

なおこの手順で確かに[tex: R^{-1}]や[tex: Q']が再構成できることは確認できたのですが、これがなぜ上手くいくのかについては残念ながら調べても分からなかりませんでした。もしご存知でしたら誰か教えてください。

### 実装
それでは実装に入りますが、先にデータをすべて使った時の回帰係数を確認しておきましょう。サンプルデータには`cars`を使い、目的変数を`dist`、説明変数を`speed`とした単回帰を回してみます。

```{r}
lm(dist ~ speed, data = cars)$coefficients
```

切片と`speed`の回帰係数がそれぞれ`-17.579`、`3.932`と推定されました。冒頭でも確認した通り、`lm`の結果は下記の方法と一致します。


```{r}
y <- cars$dist
x <- cbind(1, cars$speed)

cbind(
   solve(crossprod(x, x)) %*% crossprod(x, y),
   solve(qr.R(qr(x))) %*% t(qr.Q(qr(x))) %*% y
)
```

この数値を、分割した小集団に対する計算結果から再び得ることが目標となります。


#### 1. 共通処理
##### 1. X、yをそれぞれ小集団に分割する
それでは`x`を小集団に分割した上で解を推定していきます。今回はデータを5つに分割しましょう。`x`は50行のデータなので各データセットには10行ずつ割り当てられます。各データを`list`形式で保存しておきます。

```{r}
# 分割するデータの数
m <- 5 
n_per_d <- nrow(x) / m

# 割り切れなかった場合用
if (nrow(x) %% m != 0) m <- m + 1 

xlist <- list() # 各xの保存用リスト
ylist <- list() # 各yの保存用リスト
for (i in 1:m) {
   if(i == m) {
      xlist[[i]] = x[((i-1) * n_per_d + 1):nrow(x), ]
      ylist[[i]] = y[((i-1) * n_per_d + 1):nrow(x)]
   }
   xlist[[i]] = x[(i-1) * n_per_d + 1:n_per_d, ]
   ylist[[i]] = y[(i-1) * n_per_d + 1:n_per_d]
}
```

このような形でデータが保存されます：

```{r}
head(xlist[[1]])
```


##### 2. 各小集団のXをQR分解する
次に各小集団をQR分解し、その結果として得られる行列QおよびRをそれぞれ保存しておきましょう。リストの各要素は、更にそれぞれQとRを要素に持つリストとなります。

```{r}
QR1 <- list() # 各データセットに対するQR分解の結果を保存するリスト
for (i in 1:m) {
   QR1[[i]] <- list(Q = qr.Q(qr(xlist[[i]])),
                    R = qr.R(qr(xlist[[i]])))
}
```

この時点で`QR1`は、10行2列の行列Qと2行2列の上三角行列Rを要素に持つリストになっています。

```{r}
str(QR1)
```



#### 2. [tex: R]を計算する
##### 1. 各小集団からのRを統合する
続いて行列Rを`rbind`で一つにまとめます。

```{r}
R1 <- c()
for(i in 1:m) {
   R1 <- rbind(R1, QR1[[i]]$R)
}
```

##### 2. 再度QR分解してRを得る
この`R1`を再度QR分解します。

```{r}
R2 <- qr.R(qr(R1))
```

##### 3. Rの逆行列[tex: R^{1}]を求める
この逆行列が、当初求めようとしていたものの1つになります。

```{r}
R_inv <- solve(R2)
```


では、この`R_inv`がデータ全体を使って求めた[tex: R^{-1}]を同じ値になっているかを確認してみましょう。

```{r}
R_inv
solve(qr.R(qr(x)))
```

あれ、符号が反転していますね。



#### 3. [tex: Q']を計算する
##### 1. 1-2で得られたQを2-2で得たQに乗じる（[tex: Q']）
先ほど`R2`を計算したときと同じQR分解で、今度は行列Qを得ます。

```{r}
Q1 <- qr.Q(qr(R1))
```

さらに説明変数の数（今回は2）ごとにデータを分割します。

```{r}
## 説明変数の数
p <- ncol(x)

Q2list <- list()
for(i in 1:m) {
   Q2list[[i]] <- Q1[(i-1) * p + 1:p, ]
}
```

この`Q2list`に、最初にQR分解した結果の行列Q（`QR1$Q`）を掛け合わせます。

```{r}
Q3list <- list()
for(i in 1:m) {
   Q3list[[i]] <- QR1[[i]]$Q %*% Q2list[[i]]
}
```

ここで得られた`Q3list`はデータ全体を使ってQR分解したときの[tex: Q']になっているはずです。確認してみましょう：

```{r}
head(cbind(
   do.call("rbind", Q3list),
   qr.Q(qr(x))))
```

また符号が反転してる。。。。


#### 4. 2と3の結果およびyにより解を得る
##### 1. 3-1で得たQ'にyを乗じる
そして計算された行列を`ylist`と乗じ、結果を要素ごとに足し合わせます。

```{r}
Vlist <- list()
for(i in 1:m) {
   Vlist[[i]] <- t(Q3list[[i]]) %*% ylist[[i]]
}
```

```{r}
sumV <- Vlist[[1]]
for(i in 2:m) {
   sumV <- sumV + Vlist[[i]]
}
```

##### 2. 両者を乗じる
最後に、2-3で得た[tex: R^{-1}]と`sumV`を掛け合わせれば解が得られるはずです。どうでしょうか？

```{r}
cbind(
   R_inv %*% sumV,
   solve(crossprod(x, x)) %*% crossprod(x, y),
   solve(qr.R(qr(x))) %*% t(qr.Q(qr(x))) %*% y
)
```


同じですね！

### 終わりに
今回はデータを小集団に分割しながら線形回帰の解を推定する、ということを紹介しました。今の時代にどうしても必要な知識かと言えばそんなこともありませんが、知っておくとと良いこともあるよ、ということで。

なおこの記事で紹介したこちら()ページでは、さらに「データソースが複数に分かれている」条件でも線形回帰の解が推定できることを示しています（例えばデータを格納しているサーバーが複数に分かれており、しかもデータのコピーが難しい状況を想定しているようです）。こちらはなかなか実用的なのではないでしょうか？

https://freakonometrics.hypotheses.org/53283


### おまけ
上記の工程をtidyに実行しようとすると、以下のようになるようです（[こちら](https://github.com/ytoren/reproducible/blob/master/linear-regression-map-reduce/linear_regression_map_reduce.ipynb)から）

```{r}
library(tidyverse)
X <- data_frame(intercept = 1, speed = cars$speed) %>% as.matrix()
y <- cars$dist
mats <- X %>%
   as_data_frame() %>%
   mutate(
      id = rep(1:5, each = 10) ,
      y = y
   ) %>% 
   ## this is where partitioning happens
   nest(-id) %>% 
   mutate(
      X = map(data, ~ .x %>% select(-y) %>% as.matrix()),
      y = map(data, ~ .x %>% pull(y))
   ) %>% 
   ## We calculate QR decomposition for each partition independently
   mutate(
      Q2 = map(X, ~ .x %>% qr() %>% qr.Q()),
      R1 = map(X, ~ .x %>% qr() %>% qr.R())
   )


df_collect <- mats$R1 %>% do.call(what = 'rbind', args = .)
data.frame(dimension = c('rows', 'columns'), cbind(X %>% dim(), df_collect %>% dim()))


## Number of groups for nesting can be automatically inferred
m2 <-  dim(mats$R1[[1]])[2]

## The map-stage QR-decomposition
Q1 = df_collect %>% qr %>% qr.Q
R2 = df_collect %>% qr %>% qr.R

## For some reason this did not work with a `mutate` command...
mats$Q1 = 
   Q1 %>% 
   as_data_frame() %>% 
   mutate(id = ceiling(row_number() / m2)) %>% 
   nest(-id) %>% 
   mutate(data = map(data, ~ as.matrix(.x))) %>% 
   pull(data)

v_sum = 
   mats %>% 
   mutate(Q3_t = map2(.x = Q2, .y = Q1, .f = ~ t(.x %*% .y))) %>%
   mutate(V = map2(.x = Q3_t, .y = y, .f = ~ .x %*% .y)) %>% 
   pull(V) %>% 
   reduce(`+`)

t(solve(R2) %*% v_sum)
```

