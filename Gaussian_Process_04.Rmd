---
title: "Gaussian Process 04"
author: "ynakahashi"
date: "2019/4/7"
output: html_document
---

## 「ガウス過程と機械学習」第3章のグラフ（一部）を作図する④

前回の記事の続きです。


今回は図3.23と3.29に挑戦します。データは、陸上男子100Mについては[こちら](https://www.topendsports.com/sport/athletics/record-100m.htm)から該当する部分を取ってきました。
また久保先生の緑本からのデータはサポートサイト(http://chasen.org/~daiti-m/gpbook/data/kubo.dat)から取得しました。

まずは陸上男子100Mのデータから。一部データを除外してプロットしてみましょう。

```{r}
dat <- read.table("./Data/World_Record.dat", sep = "\t",
                  col.names = c("name", "time", "date"))

dat <- dat[-c(6, 17:21), -1]
dat$date <- as.integer(gsub(".*, ", "", dat$date))
colnames(dat) <- c("y", "x")
plot(dat$x, dat$y, xlab = "year", ylab = "time", 
     xlim = c(1960, 2020), ylim = c(9.5, 10.1), pch = 4, cex = 2)
```

```{r}
# tmp <- read.table("./Data/World_Record.dat", sep = "\t",
#                   col.names = c("name", "time", "date"))
# tmp <- tmp[-c(6, 17:21), -1]
# tmp$date <- as.integer(gsub(".*, ", "", tmp$date))
# colnames(tmp) <- c("y", "x")
```

本で使われているデータとは少し違っている様子ですが、このまま進めます。

本にしがたい、Xおよびyを平均0、分散1にスケーリングします。`scale`を使いますが、`dat`は`data.frame`で持っておきたいのでスケーリングのパラメータは別に取っておきましょう。


```{r}
dat <- scale(dat)
scale_pars <- unlist(attributes(dat)[c("scaled:center", "scaled:scale")])
dat <- as.data.frame(dat)
```

まずはこのデータに対してシンプルにRBFカーネルで推定してみます。前回の記事で定義した関数を色々使いまわすことにします。まずは`L`、これはハイパーパラメータを与えたときに対数尤度を返す関数でした。

```{r}
L <- function(param, x, y) {
   # C <- -nrow(train)/2*log(2*pi)
   C <- 0
   K <- get_cov_mat_exp(x, x, theta1 = param[1], theta2 = param[2])
   diag(K) <- diag(K) + exp(param[3])
   
   return(-log(det(K)) - t(as.matrix(y)) %*% solve(K) %*% as.matrix(y) + C)
}
```

`L`の中で使われている`get_cov_mat_exp`も定義しましょう。これは共分散行列を得る関数です。

```{r}
get_cov_mat_exp <- function(x1, x2, theta1 = 1, theta2 = 1) {
   
   ## matrixに変換
   x1 <- as.matrix(x1)
   x2 <- as.matrix(x2)
   
   ## 行の組み合わせを作成する
   n <- nrow(x1)
   m <- nrow(x2)
   d <- ncol(x1)
   tmp <- cbind(kronecker(x1, matrix(1, m)), kronecker(matrix(1, n), x2))
   
   ret <- apply(tmp, 1, function(x, d, theta1, theta2) {
      rbf_knl_exp(x[(1:d)], x[(d+1):ncol(tmp)], theta1, theta2) # rbf_knl_expを使う
   }, d, theta1, theta2)
   return(matrix(ret, n, m, byrow = T))
}
```


さらに`rbf_knl_exp`も使います。

```{r}
rbf_knl_exp <- function(x1, x2, theta1 = 1, theta2 = 1) {
   exp(theta1) * exp(-norm(x1 - x2, "2")^2/exp(theta2))
}
```


上記の関数はパラメータ探索における効率化のためにパラメータは`log`を取ってから与えることを前提としていましたが、可視化用に元の関数も定義しておきましょう。

```{r}
get_cov_mat <- function(x1, x2, theta1 = 1, theta2 = 1) {
   
   ## matrixに変換
   x1 <- as.matrix(x1)
   x2 <- as.matrix(x2)
   
   ## 行の組み合わせを作成する
   n <- nrow(x1)
   m <- nrow(x2)
   d <- ncol(x1)
   tmp <- cbind(kronecker(x1, matrix(1, m)), kronecker(matrix(1, n), x2))
   
   ret <- apply(tmp, 1, function(x, d, theta1, theta2) {
      rbf_knl(x[(1:d)], x[(d+1):ncol(tmp)], theta1, theta2)
   }, d, theta1, theta2)
   return(matrix(ret, n, m, byrow = T))
}
```

```{r}
rbf_knl <- function(x1, x2, theta1 = 1, theta2 = 1) {
   theta1 * exp(-norm(x1 - x2, "2")^2/theta2)
}
```



ではこれらの関数を使い、今回のデータでハイパーパラメータの最適化を実行してみましょう。

```{r}
param <- c(1, 1, 1)
res_par <- 
   optim(par = optim(par = param, fn = L, x = dat$x, y = dat$y, 
                     control = list(fnscale = -1))$par,
         fn = L, x = dat$x, y = dat$y, control = list(fnscale = -1))
```

```{r}
print(exp(res_par$par), digits = 3)
L(res_par$par, dat$x, dat$y)
```



```{r}
gen_gpreg_plot <- function(param, x, y) {

   min_y <- 9.4
   max_y <- 10.1
   min_x <- -2
   max_x <- 1.7

   test <- seq(min_x, max_x, 0.05)

   theta1 <- exp(param[1])
   theta2 <- exp(param[2])
   theta3 <- exp(param[3])
   
   K       <- get_cov_mat(x, x, theta1 = theta1, theta2 = theta2)
   diag(K) <- diag(K) + theta3
   k       <- get_cov_mat(x, test, theta1 = theta1, theta2 = theta2)
   s       <- get_cov_mat(test, test, theta1 = theta1, theta2 = theta2)
   diag(s) <- diag(s) + theta3
   Mu      <- t(k) %*% solve(K) %*% y * scale_pars["scaled:scale.y"] +
      scale_pars["scaled:center.y"]
   Var     <- (s - t(k) %*% solve(K) %*% k) * sqrt(scale_pars["scaled:scale.y"])
   # CI_u    <- Mu + 2 * sqrt(diag(Var))
   # CI_l    <- Mu - 2 * sqrt(diag(Var))
   CI_u    <- Mu + 0.5 * sqrt(diag(Var))
   CI_l    <- Mu - 0.5 * sqrt(diag(Var))
   
   x <- x * scale_pars["scaled:scale.x"] + scale_pars["scaled:center.x"]
   y <- y * scale_pars["scaled:scale.y"] + scale_pars["scaled:center.y"]
   test <- test * scale_pars["scaled:scale.x"] + scale_pars["scaled:center.x"]
   min_x <- min_x * scale_pars["scaled:scale.x"] + scale_pars["scaled:center.x"]
   max_x <- max_x * scale_pars["scaled:scale.x"] + scale_pars["scaled:center.x"]
   xlim <- c(min_x, max_x)
   ylim <- c(min_y, max_y)
   
   plot(x, y, xlim = xlim, ylim = ylim, type = "n")
   polygon(c(test, rev(test)), c(CI_u, rev(CI_l)), col = 'gray', border = NA)
   points(x, y, xlim = xlim, ylim = ylim, xlab = "x", pch = 4, cex = 2)
   lines(test, Mu, xlim = xlim, ylim = ylim, type = "l", ylab = "")

}
```



```{r}
gen_gpreg_plot(res_par$par, dat$x, dat$y)
```



```{r}
book_par <- c(log(1.62), log(0.44), log(0.06))
gen_gpreg_plot(book_par, dat$x, dat$y)
```





