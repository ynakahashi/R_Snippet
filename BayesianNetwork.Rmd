---
title: "BayesianNetwork"
author: "Y.Nakahashi"
date: "2018/1/10"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### 目的
*Bayesian Network*により変数間の関連性を図示し，かつその強さを定量的に示したい．

----

### 分析環境の準備
#### ライブラリの読み込み

```{r}
suppressMessages(library(BNSL))
suppressMessages(library(bnlearn))
```

#### サンプルデータの作成
[こちらの記事](http://d.hatena.ne.jp/isseing333/20100604)を参考にサンプルデータを作成した．一部の係数を修正したが，記事同様にHeightとSBPがBMIに刺さり，BMIがFBSに刺さる構造となっている．

```{r}
set.seed(123)
norm <- rnorm(4000)
Data <- matrix(norm, nrow = 1000, ncol = 4, byrow = T)
colnames(Data) <- c("Height", "BMI", "SBP", "FBS")

Data2 <- Data <- as.data.frame(Data)
Data2$Height <- 170 + Data$Height * 10
Data2$SBP    <- 120 + Data$SBP * 10
Data2$BMI    <- 22  + Data$Height * 5 + Data$SBP * 5
Data2$FBS    <- 90  + (Data2$BMI - 22) * 5 + Data$FBS * 10
formattable::formattable(head(Data2))
```


### 分析実行
#### 構造学習
Bayesian Networkはデータから変数間の関連性を推定する構造学習と，推定された構造を元にパラメータを推定するフィッティングの二段階で実施される．構造学習のアルゴリズムには*Grow-Shrink*を指定．Webだと*Hill-Climbing*が使われる事が多い様子だが，先ほど参照した記事によると*Grow-Shrink*はグラフ理論による裏付けがあるとのこと．

```{r}
str_01_gs <- gs(Data2)
str_01_hc <- hc(Data2)
par(mfrow = c(1, 2))
plot(str_01_gs)
plot(str_01_hc)
```

gsでは設定した通りの構造が推定されたが，hcではBMIとSBPの関係性が逆転している．

#### フィッティング
この構造を用いてパラメータを推定する．なおここで得られる係数は，個別にlmをかけたものと同じとなり，例えばBMIであればlm(BMI ~ Height + SBP)と等しい．

```{r}
fit_01 <- bn.fit(str_01_gs, Data2)
(coef_01 <- coefficients(fit_01))
```

```{r}
coef(lm(BMI ~ Height + SBP, Data2))
```

----

### 分析実行その２
#### 構造学習
次にサンプルデータの*gaussian.test*を用いてパラメータの推定を行う．元の構造はわからないが*gs*によって推定した形は以下のよう．

```{r}
str_02 <- gs(gaussian.test)
plot(str_02)
```

#### フィッティング
グラフの構造が悪く，フィッティングできない．

```{r}
fit_02 <- bn.fit(str_02, gaussian.test)
```

str_02の中身を確認すると，modelが[partially directed graph]となっていることがわかる．またarcsのundirected arcsが1になっている．

```{r}
str_02
```

再度str_02の構造を確認すると，ノードBD間のエッジが無向になっていることがわかる．

```{r}
plot(str_02)
```


そこでB -> Dのエッジを設定してみる．undirected arcsが0となり，modelがpartially directed graphではなくノード間の関連性を表したものとなっていることを確認する．

```{r}
(str_03 <- set.arc(str_02, "B", "D"))
plot(str_03)
```

この構造を用いて再度フィッティングしてみる．

```{r}
fit_03 <- bn.fit(str_03, gaussian.test)
(coef_03 <- coefficients(fit_03))
```

今度は上手くいった！

----

### 分析実行その３
続いて直接効果と間接効果の分離を試みる．再度*gs*で構造を推定し，B -> Dのエッジと共にB -> Fのエッジも追加する．これでBはFに対して直接刺さるエッジとDを経由してFに刺さるエッジを持つことになる．

```{r}
str_04 <- set.arc(str_03, "B", "F")
par(mfrow = c(1, 3))
plot(str_02) # gsで推定した構造
plot(str_03) # B -> Dに修正
plot(str_04) # B -> Fを追加
```


```{r}
fit_04 <- bn.fit(str_04, gaussian.test)
coefficients(fit_04)
coefficients(fit_03)
```

```{r}
coef(lm(F ~ A + B + D + E + G, gaussian.test))
```

Bの変動による寄与はほとんどDを経由してFに影響しているようで，BのFへの直接の効果はなさそう．

----

### 分析実行その４
#### 構造学習
今度は構造の推定に*BNSL*を試してみる．

```{r}
str_05 <- bnsl(gaussian.test)
plot(str_05)
```

bnlearn::gsを用いた時と比べて構造がかなり異なる．比較してみる．

```{r}
par(mfrow = c(1, 2))
plot(str_02)
plot(str_05)
```

"A -> C"や"G -> F"など，方向性が逆転する関係が見られる．Eも独立してしまった．

#### フィッティング
この構造でフィッティングしてみる．フィッティング自体はbnlearn::bn.fitを用いる．

```{r}
fit_05 <- bn.fit(str_05, gaussian.test)
coefficients(fit_05)
```


----


----

### 分析実行その５
さらに続いて，データを標準化した場合の結果も確認してみる．*scale*でデータを標準化する．

```{r}
my_gaussian <- as.data.frame(scale(gaussian.test))
str_06 <- bnsl(my_gaussian)
par(mfrow = c(1, 2))
plot(str_04)
plot(str_06)
```

標準化すると構造が変わってしまう．

```{r}
fit_06 <- bn.fit(str_06, my_gaussian)
coefficients(fit_06)
```

----

### 分析実行その６
ライブラリ{MASS}に格納されているサンプルデータbirthwtを用いて推定してみる（ただしbnlearnではintegerは使えないのでnumericに変換し，変数も一部に限定する）．

#### 構造学習
構造学習のアルゴリズムには*Hill-Climbing*を指定．

```{r}
vars <- c("low", "race", "smoke", "ht", "ui")
my_birthwt <- as.data.frame((do.call("cbind", lapply(birthwt[, vars],
                                                     as.numeric))))
str_01 <- hc(my_birthwt)
plot(str_01)
```



```{r}
str_07 <- gs(learning.test)
str_08 <- gs(learning.test, optimized = TRUE)
par(mfrow = c(1, 2))
plot(str_07)
plot(str_08)
```

```{r}
str_09 <- set.arc(str_07, "A", "B")
bn.fit(str_09, learning.test, method = "mle")
bn.fit(str_09, learning.test, method = "bayes")
```

