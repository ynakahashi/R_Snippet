---
title: "GAMをもう少し理解したい"
output: html_document
---
[contents:]

### 背景
業務でモデリングを行うとき、私は大抵の場合GLMから始めます。目的変数に合わせて柔軟に分布を選択することが可能で、回帰係数という極めて解釈性の高い結果を得ることができるというのが理由です。

一方でGLMを使っていて不満に感じることの一つが、（\eta の世界で）非線形な効果を表現できないという点です。もちろん２次・３次の項や交互作用項を追加することである程度それらの不満は解消できるのですが、もう少しデータからそれらの特徴を学習したいと思うことがあります。

今回取り上げる一般化加法モデル（Generalized Additive Model, GAM）は、そのような複雑な関連性を表現できるよう説明変数に非線形な変換を行うもので、GLMを拡張したものとなります。ちょっと古いですが、2015年にMicrosoft RearchがKDDに出した論文[PDF](http://people.dbmi.columbia.edu/noemie/papers/15kdd.pdf)では、GAMを指して「*the gold standard for intelligibility when low-dimensional terms are considered*」と言っており、解釈性を保ちつつ高い予測精度を得ることができるモデルとしています。なおこの論文ではGAMに２次までの交互作用を追加するGA2Mという手法を提案しています。

このGAMの実装について調べた内容を書き留めておきます。GAMがどういうものかとか、平滑化に関する説明は、他に良いページがありますのでそちらを参照してください。例えば：
https://logics-of-blue.com/%E5%B9%B3%E6%BB%91%E5%8C%96%E3%82%B9%E3%83%97%E3%83%A9%E3%82%A4%E3%83%B3%E3%81%A8%E5%8A%A0%E6%B3%95%E3%83%A2%E3%83%87%E3%83%AB/

http://testblog234wfhb.blogspot.com/2014/07/generalized-additive-model.html

https://blog.datarobot.com/jp/2017/10/24/ga2m-and-rating-table


### GAMの実行結果
始めに、GAMを使うとどのような結果を得ることができるのか確認しましょう。ちなみに検証した環境は以下の通りです。

```{r}
sessionInfo()
```


GAMの実装としてRでは {mgcv}が使われることが多いようですが、今回は「Rによる統計的学習入門」を参考に{gam}を使用しました。ちなみに、この本は統計・機械学習の主要な手法を網羅的に押さえつつ章末にRでの実行方法が紹介されており、大変勉強になる良書です。

Rによる統計的学習入門

同書で用いているサンプルデータ `Wage` を使用するため、{ISLR}を同時に読み込みます。この{ISLR}パッケージは上記の本の原著である*Introduction of Statistical Learning with Applications in R*から来ているようです。またこのデータは、アメリカの大西洋岸中央部における男性3000人の賃金、および年齢や婚姻状況、人種や学歴などの属性が記録されています。


```{r}
library(gam)
library(ISLR)
```

データの中身を見てみましょう。

```{r}
head(Wage)
```


このデータを用いて早速フィッティングしてみましょう。 `glm` と同様に関数 `gam` でモデルを当てはめることができます。

```{r}
res_gam <- gam(wage ~ s(year, 4) + s(age, 5) + education, data = Wage)
```

ここで `s(age, 5)` は、説明変数 `year` を平滑化した上でモデルに取り込むことを意味し、5は平滑化の自由度です。なお `s()` の時点ではまだ平滑化は行われておらず、平滑化に必要な情報を属性として付与しているだけのようです。

```{r}
head(s(Wage$age, 5))
```

ではフィッティングした結果を見てみましょう。

```{r}
summary(res_gam)
```

パッと見ると、 `glm` を当てはめたときと同様の結果が得られるようです。実際、 `gam` の本体（と思われる） `gam.fit` の中では `stats::lm.wfit` が呼ばれます。

しかし、 `glm` の結果と大きく異なる点として、各説明変数の回帰係数が出ていません。これはどういうことでしょう。以下のように説明変数の効果をプロットしてみます。

```{r}
par(mfrow = c(1, 3))
plot(res_gam, se = TRUE, col = "blue")
```

`age` が分かりやすいですが、この変数は34までは0未満となっており、  `age`  は35歳程度まで `wage`  の平均を下回っていることがわかります。その後45歳をピークに減少傾向に入り、65歳を過ぎると再び平均を下回るようになり、以降は急激に減少していきます。このような現象は、年齢とともに役職が上がることで賃金が増加し、退職によって減少することを考えれば非常に納得感のあるものだと思います。

なお上のプロットに必要なデータは以下のように取れるので、説明変数の各点における目的変数に対する影響を数値でも確認できます（必要な関数がエクスポートされていないので `gam:::` で直接呼び出しています）。

```{r}
tmp <- gam:::preplot.Gam(res_gam, terms = gam:::labels.Gam(res_gam))
age_sm <- cbind(tmp$`s(age, 5)`$x, tmp$`s(age, 5)`$y) 
age_sm_uniq <- unique(age_sm[order(age_sm[, 1]), ])
```

プロットしてみましょう。同じ線が描けます。

```{r}
plot(age_sm_uniq, type = "l", xlab = "age", ylab = "s(age, 5)")
```

さて、上記の結果は例えば `age` の二次の項を含めることで `lm` でも再現できるかもしれません。例えば以下のようになります：

```{r}
res_lm <- lm(wage ~ year + poly(age, 2) + education, Wage)
x_lm <- seq(min(Wage$age), max(Wage$age), length.out = 100)
nd <- data.frame(year = rep(2003, 100),
                 age = x_lm,
                 education = rep("2. HS Grad"))
prd_lm <- predict(res_lm, nd, se.fit = T)


prd_m <- mean(prd_lm$fit)
prd_m <- 90
plot(x_lm, prd_lm$fit - prd_m, type = "l", col = "blue", ylim = c(-40, 10))
lines(x_lm, prd_lm$fit - prd_m + 2*prd_lm$se.fit, lty = "dashed")
lines(x_lm, prd_lm$fit - prd_m - 2*prd_lm$se.fit, lty = "dashed")
```

大体同じようなプロットを作成する事ができました。しかしピークを過ぎてからの緩やかな減少は表現できていませんし、一つ一つの変数について何次までの多項式を含めるかを検討していくのは少し手間がかかります。GAMを使えばデータに存在する細やかな変化を自動的に捉えることができます（もちろん代償もあります）。



### GAMの実装
それでは `gam` がどのようにフィッティングを行っているのかを見ていきましょう。本体は最後の方に出てくる `gam.fit` なのですが、途中も少し細かく追ってみます。

```{r}
### gam(wage ~ s(year, 4) + s(age, 5) + education, data = Wage)
### gam::gam
function (formula, family = gaussian, data, weights, subset, 
    na.action, start = NULL, etastart, mustart, control = gam.control(...), 
    model = TRUE, method = "glm.fit", x = FALSE, y = TRUE, ...) 
{
    ### 関数の引数を名前付きで確定。gam(wage ~ s(year, 4) + education, Wage)として与えた場合、
    ### formula = と data = がそれぞれ保持される。
    ### match.call returns a call in which all of the specified arguments are specified by their full names.
    call <- match.call()

    ### familyの判定
    if (is.character(family)) 
        family <- get(family, mode = "function", envir = parent.frame())
    if (is.function(family)) 
        family <- family()
    if (is.null(family$family)) {
        print(family)
        stop("`family' not recognized")
    }

    ### データが指定されていない場合？
    if (missing(data)) 
        data <- environment(formula)
    
    ### 指定されている引数の取り出し
    mf <- match.call(expand.dots = FALSE)
    m <- match(c("formula", "data", "subset", "weights", "etastart", 
        "mustart", "offset"), names(mf), 0L)
    mf <- mf[c(1L, m)]

    ### 指定されていない引数を指定し、stats::model.frame()の形式に仕立てる
    mf$na.action = quote(na.pass)
    mf$drop.unused.levels <- TRUE
    mf[[1L]] <- quote(stats::model.frame)
```

ここまでは `gam` にオプションとして指定した内容に沿った処理を実行しています。

```{r}
    ### 平滑化の関数を取ってくる（s, lo, random)
    gam.slist <- gam.smoothers()$slist
```

ここで一つ `gam` ならではの処理があり、平滑化に使う関数を取り出しています。 新しい平滑化関数を指定することも出来るようですが、デフォルトは `s` 、 `lo` および `random` で、それぞれ **平滑化スプライン**、**局所回帰**、**ランダム効果としての指定**を意味しているようです。 3つめの `random` がわからなかったので調べてみたところ、これは質的変数に対する指定で、パラメータの推定においていわゆる縮小推定を行なうもののようでした。

https://www.rdocumentation.org/packages/gam/versions/1.16.1/topics/random

これらに接頭語として `gam` を加えた（e.g. `gam.s`）関数が平滑化のための関数として実行されます。 `gam.s` については後述します。

```{r}
    ### term を mf$formula に渡す
    mt <- if (missing(data)) 
        terms(formula, gam.slist)
    else terms(formula, gam.slist, data = data)
    mf$formula <- mt

    ### ここで mf 、つまり model.frame が実行されて data.frame になる
    ### ただし平滑化は実行されず、平滑化のパラメータは attribute として持っている
    mf <- eval(mf, parent.frame())
    if (missing(na.action)) {
        naa = getOption("na.action", "na.fail")
        na.action = get(naa)
    }
    mf = na.action(mf)
    mt = attributes(mf)[["terms"]]
```

ここまで `mf` は `call` クラス、すなわち未評価の関数およびその引数を要素に持つオブジェクトでした。それが `eval` で評価されたため `stats::model.frame` が実行され、 `formula` にしたがい `data.frame` が生成された、という流れのようです（間違っていたらすみません）。


```{r}
    ### method の指定によって処理を分ける。 glm.fit または glm.fit.null 以外の場合はエラー
    switch(method, model.frame = return(mf), glm.fit = 1, glm.fit.null = 1, 
        stop("invalid `method': ", method))
    
    ### Y
    Y <- model.response(mf, "any")

    ### X を matrix で。
    ### gamを実行したときのエラーメッセージ（ `non-list contrasts argument ignored` ）はここで出ている。 contrasts の指定が良くない様子。
    X <- if (!is.empty.model(mt)) 
      model.matrix(mt, mf, contrasts) 
    else matrix(, NROW(Y), 0)

    ### その他パラメータ（weights, offset, mustart, etastart）
    weights <- model.weights(mf)
    offset <- model.offset(mf)
    if (!is.null(weights) && any(weights < 0)) 
        stop("Negative wts not allowed")
    if (!is.null(offset) && length(offset) != NROW(Y)) 
        stop("Number of offsets is ", length(offset), ", should equal ", 
            NROW(Y), " (number of observations)")
    mustart <- model.extract(mf, "mustart")
    etastart <- model.extract(mf, "etastart")

    ### ここが本体。 gam.fit を呼び出している
    fit <- gam.fit(x = X, y = Y, smooth.frame = mf, weights = weights, 
        start = start, etastart = etastart, mustart = mustart, 
        offset = offset, family = family, control = control)
    
    ### offset が指定されており intercept 項がある場合
    if (length(offset) && attr(mt, "intercept") > 0) {
        fit$null.dev <- glm.fit(x = X[, "(Intercept)", drop = FALSE], 
            y = Y, weights = weights, offset = offset, family = family, 
            control = control[c("epsilon", "maxit", "trace")], 
            intercept = TRUE)$deviance
    }
    if (model) 
        fit$model <- mf
    fit$na.action <- attr(mf, "na.action")
    if (x) 
        fit$x <- X
    if (!y) 
        fit$y <- NULL
    fit <- c(fit, list(call = call, formula = formula, terms = mt, 
        data = data, offset = offset, control = control, method = method, 
        contrasts = attr(X, "contrasts"), xlevels = .getXlevels(mt, 
            mf)))
    class(fit) <- c("Gam", "glm", "lm")
    if (!is.null(fit$df.residual) && !(fit$df.residual > 0)) 
        warning("Residual degrees of freedom are negative or zero.  This occurs when the sum of the parametric and nonparametric degrees of freedom exceeds the number of observations.  The model is probably too complex for the amount of data available.")
    fit
}
```









```{r}
# fit <- lm(wage ~ poly(age, 4), data = Wage)
# coef(summary(fit))
# tmp <- head(cbind(Wage$age, poly(Wage$age, 4)))
# tmp
# fit2 <- lm(wage ~ poly(age, 4, raw = T), data = Wage)
# coef(summary(fit2))
# tmp2 <- head(cbind(Wage$age, poly(Wage$age, 4, raw = T)))
# tmp2
# tmp2[, 2]^2
# tmp2[, 2]^3
# tmp2[, 2]^4
```













```{r}
agelims <- range(Wage$age)
age.grid <- seq(from = agelims[1], to = agelims[2])
preds <- predict(fit, newdata = list(age = age.grid), se = TRUE)
se.bands <- cbind(preds$fit + 2 * preds$se.fit, preds$fit - 2 * preds$se.fit)
par(mfrow = c(1, 1), mar = c(4.5, 4.5, 1, 1), oma = c(0, 0, 4, 0))
plot(Wage$age, Wage$wage, xlim = agelims, cex = .5, col = "darkgrey")
title("Quad Polynomial", outer = T)
lines(age.grid, preds$fit, lwd = 2, col = "blue")
matlines(age.grid, se.bands, lwd = 1, col = "blue", lty = 3)
```




```{r}
library(splines)
```



```{r}
plot(Wage$age, ns(Wage$age))
```


```{r}
par(mfrow = c(2, 2), cex = .5)
plot(ns(Wage$age, df = 4)[, 1], Wage$wage)
plot(ns(Wage$age, df = 4)[, 2], Wage$wage)
plot(ns(Wage$age, df = 4)[, 3], Wage$wage)
plot(ns(Wage$age, df = 4)[, 4], Wage$wage)
```



```{r}
plot(Wage$age, Wage$wage, xlim = agelims, cex = .5, col = "darkgrey")
title("Smooth spline")
fit <- smooth.spline(Wage$age, Wage$wage, df = 16)
fit2 <- smooth.spline(Wage$age, Wage$wage, cv = TRUE)
fit2$df
lines(fit, col = "red", lwd = 2)
lines(fit2, col = "blue", lwd = 2)
legend("topright", legend = c("16 DF", "6.8 DF"),
       col = c("red", "blue"), lty = 1, lwd = 2, cex = .8)
```

```{r}
plot(Wage$age, Wage$wage, xlim = agelims, cex = .5, col = "darkgrey")
title("Loess")
fit = loess(wage ~ age, span = .2, data = Wage)
fit2 = loess(wage ~ age, span = .5, data = Wage)
lines(age.grid, predict(fit, data.frame(age = age.grid)),
      col = "red", lwd = 2)
lines(age.grid, predict(fit2, data.frame(age = age.grid)),
      col = "blue", lwd = 2)
legend("topright", legend = c("Span = 0.2", "Span = 0.5"),
       col = c("red", "blue"), lty = 1, lwd = 2, cex = .8)
```



```{r}
gam1 <- lm(wage ~ ns(year, 4) + ns(age, 5) + education, data = Wage)
coef(summary(gam1))
```

```{r}
plot(gam1)
```

```{r}
library(gam)
```

```{r}
gam.m3 <- gam(wage ~ s(year, 4) + s(age, 5) + education, data = Wage)
```

```{r}
par(mfrow = c(1, 3))
plot(gam.m3, se = TRUE, col = "blue")
```

`gam1` は `lm` で当てはめているが `plot.Gam` が利用できる

```{r}
par(mfrow = c(1, 3))
plot.Gam(gam1, se = TRUE, col = "red")
```


平滑化スプラインを使う場合は `lm` ではなく `gam` を使わないとまともに計算できない

```{r}
gam.m4 <- lm(wage ~ s(year, 4) + s(age, 5) + education, data = Wage)
```
```{r}
par(mfrow = c(1, 3))
plot.Gam(gam.m4, se = TRUE, col = "red")
```


```{r}
gam.lo <- gam(wage ~ s(year, 4) + lo(age, span = 0.7) + education,
              data = Wage)
```

```{r}
par(mfrow = c(1, 3))
plot.Gam(gam.lo, se = TRUE, col = "blue")
```


```{r}
gam.lo.i <- gam(wage ~ lo(year, age, span = 0.5) + education,
                data = Wage)
```

```{r}
# install.packages("akima")
library(akima)
```

```{r}
plot(gam.lo.i)
```


```{r}
gam.lr <- gam(I(wage > 250) ~ year + s(age, 5) + education,
              family = "binomial", data = Wage)
```

```{r}
par(mfrow = c(1, 3))
plot(gam.lr, se = TRUE, col = "blue")
```

```{r}
gam.lr.s <- gam(I(wage > 250) ~ year + s(age, 5) + education,
                family = "binomial", data = Wage, 
                subset = (education != "1. < HS Grad"))
par(mfrow = c(1, 3))
plot(gam.lr.s, se = TRUE, col = "blue")
```


モデルオブジェクトが `smooth` を持つか
```{r}
is.null(gam.m4$smooth)
```

```{r}
is.null(gam.m3$smooth)
```


新規データに対してはSEは出せない

```{r}
nd <- head(Wage, 5)
predict(gam.m3, nd, se.fit = TRUE)
```



まずは `predict.glm` で予測値を求める。当然答えは異なる。

```{r}
predict.glm(gam.m3, nd)
predict.Gam(gam.m3, nd)
```


使用している変数で model.frame を作成する

```{r}
Terms <- delete.response(gam.m3$terms)
model.frame(Terms, nd)
```


```{r}
!is.null(cl <- attr(Terms, "dataClasses"))
```

```{r}
smooth.frame <- model.frame(Terms, nd, na.action = na.fail, 
                            xlev = gam.m3$xlevels)
.checkMFClasses(cl, smooth.frame)
```


モデルオブジェクトから平滑化された説明変数の列名を取ってくる。
上で作った `smooth.frame` ではなく、モデルオブジェクトに格納された
`smooth.frame` なので注意。

```{r}
nrows <- nrow(nd)
smooth.labels <- names(gam.m3$smooth.frame)
n.smooths <- length(smooth.labels)
pred.s <- array(0, c(nrows, n.smooths), list(row.names(smooth.frame), 
            smooth.labels))
pred.s
```



```{r}
terms <- labels(gam.m3)
smooth.labels[match(smooth.labels, terms, 0) > 0]
```

モデルオブジェクトの `smooth.frame` において該当する列の "call" アトリビューションを取り出す
```{r}
TT <- "s(year, 4)"
Call <- attr(gam.m3$smooth.frame[[TT]], "call")
Call
```

上記にオプションを追加する。 `Call` は `call` クラスであり、
List における各要素にオプションを持つ感じ。

```{r}
Call$xeval <- substitute(smooth.frame[[TT]], list(TT = TT))
Call
```


データの各点の重み w と、上で作った z を渡して `gam.s` を呼ぶ。
`data` オブジェクトの代わりにモデルオブジェクトの `smooth.frame` を渡す。
`spar` はスムージングパラメータ、 `df` は平滑化の自由度。 `df` が指定されている場合はこちらが使われる

```{r}
w <- gam.m3$weights
z <- gam.m3$residuals + gam.m3$smooth[, TT]
# pred.s[, TT] <- eval(Call)
pred.s <- gam.s(gam.m3$smooth.frame[[TT]], z, w, spar = 1, df = 4, xeval = smooth.frame[[TT]])
```


`df` を指定した状態で `spar` を変えても予測値は変わらないはず。

```{r}
gam.s(gam.m3$smooth.frame[[TT]], z, w, spar = 0.8, df = 4, xeval = smooth.frame[[TT]])
gam.s(gam.m3$smooth.frame[[TT]], z, w, spar = 1.2, df = 4, xeval = smooth.frame[[TT]])
```

`df` を0にすると `spar` が使われる

```{r}
gam.s(gam.m3$smooth.frame[[TT]], z, w, spar = 0.8, df = 0, xeval = smooth.frame[[TT]])
gam.s(gam.m3$smooth.frame[[TT]], z, w, spar = 1.2, df = 0, xeval = smooth.frame[[TT]])
```

`df` を1以上で変化させると予測値が変わる

```{r}
gam.s(gam.m3$smooth.frame[[TT]], z, w, spar = 1, df = 2, xeval = smooth.frame[[TT]])
gam.s(gam.m3$smooth.frame[[TT]], z, w, spar = 1, df = 4, xeval = smooth.frame[[TT]])
```




