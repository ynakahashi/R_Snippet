---
title: "R Notebook"
Date: 2018-01-12
Authour: Y.Nakahashi
output: html_notebook
---

### 内容
[こちらの記事](https://tensorflow.rstudio.com/blog/keras-customer-churn.html)を基にKerasを用いて離反予測を行う。また{lime}による結果の解釈を試みる。

   1. 分析環境設定
   1. データのロードと前処理
   1. モデリングと精度評価
   1. 結果の解釈

### 1. 分析環境設定
#### 必要なライブラリのインストール
```{r}
pkgs <- c("keras", "lime", "tidyquant", "rsample", "recipes", 
          "yardstick", "corrr")
install.packages(pkgs)
```

#### ライブラリのロード
```{r}
library(keras)
library(lime)
library(tidyquant)
library(rsample)
library(recipes)
library(yardstick)
library(corrr)
```

#### Kerasのインストール
初めての場合、結構時間がかかる。

```{r}
# install_keras()
```

以上で分析環境の設定は完了

### 2.データのロードと前処理
#### データの読み込み
IBM Watson Telco Datasetとして公開されているデータを使用する。

```{r}
churn_data_raw <- read_csv("/Users/ynakahashi/Desktop/ynakahashi_git/R_Snippet/Data/WA_Fn-UseC_-Telco-Customer-Churn.csv")
glimpse(churn_data_raw)
```

### 不要なデータの削除
顧客IDのようにユニークな列やNAを含む行を削除し、並び替え。

```{r}
churn_data_tbl <- 
   churn_data_raw %>%
   select(-customerID) %>%
   drop_na() %>%
   select(Churn, everything())

glimpse(churn_data_tbl)
```

### データを学習用と検証用に分割
{rsample}パッケージを用いることで、簡単に分割できる。

```{r}
set.seed(100)
train_test_split <- initial_split(churn_data_tbl, prop = 0.8)
train_test_split

# Retrieve train and test sets
train_tbl <- training(train_test_split)
test_tbl  <- testing(train_test_split) 
```

### 変数変換
TotalChargesの対数変換が有効であるかを確認する。{corrr}パッケージの関数を使い体裁を整える。
```{r}
train_tbl %>%
   select(Churn, TotalCharges) %>%
   mutate(Churn = Churn %>% as.factor() %>% as.numeric(),
          LogTotalCharges = log(TotalCharges)) %>%
   correlate() %>%
   focus(Churn) %>%
   fashion()
```



### データ前処理レシピ作成
{recipe}パッケージでデータの前処理の手順を定義した**レシピ**を作成する。
```{r}
rec_obj <- 
   recipe(Churn ~ ., data = train_tbl) %>% # 目的変数と説明変数の定義
   step_discretize(tenure, options = list(cuts = 6)) %>% # 連続変数のカテゴリ化
   step_log(TotalCharges) %>% # 対数変換
   step_dummy(all_nominal(), -all_outcomes()) %>% # カテゴリ変数のダミー化
   step_center(all_predictors(), -all_outcomes()) %>% # 説明変数の中心化
   step_scale(all_predictors(), -all_outcomes()) %>% # 説明変数のスケーリング
   prep(data = train_tbl) # レシピの完成

rec_obj
```

### 前処理の実行
作成したレシピに基づき、データに前処理を施す。

```{r}
x_train_tbl <- bake(rec_obj, newdata = train_tbl) %>% select(-Churn)
x_test_tbl  <- bake(rec_obj, newdata = test_tbl) %>% select(-Churn)

glimpse(x_train_tbl)
```

### 目的変数
目的変数もダミー化しておく。

```{r}
y_train_vec <- ifelse(pull(train_tbl, Churn) == "Yes", 1, 0)
y_test_vec  <- ifelse(pull(test_tbl, Churn) == "Yes", 1, 0)
```

## 3.モデリングと精度評価
Kerasを用いてディープラーニングのモデルを定義する。

```{r}
model_keras <- keras_model_sequential()
model_keras %>% 
   
   # 隠れ層の一つ目はユニット数を16とする。第一層なので入力は説明変数の数。
   layer_dense(
      units              = 16, 
      kernel_initializer = "uniform", 
      activation         = "relu", 
      input_shape        = ncol(x_train_tbl)) %>% 
   
   # 過学習を防ぐためのドロップアウト
   layer_dropout(rate = 0.1) %>%
   
   # 隠れ層の二つ目もユニット数を16とする
   layer_dense(
      units              = 16, 
      kernel_initializer = "uniform", 
      activation         = "relu") %>% 
   
   # 過学習を防ぐためのドロップアウト
   layer_dropout(rate = 0.1) %>%
   
   # 出力層。活性化関数はsigmoid
   layer_dense(
      units              = 1, 
      kernel_initializer = "uniform", 
      activation         = "sigmoid") %>% 
   
   # 勾配法：Adam、損失関数：クロスエントロピー、精度指標：accuracy
   compile(
      optimizer = 'adam',
      loss      = 'binary_crossentropy',
      metrics   = c('accuracy')
   )

model_keras
```

### フィッティング
上記のモデルに従いフィッティングを行う。
```{r}
history <- fit(
   object           = model_keras, 
   x                = as.matrix(x_train_tbl), 
   y                = y_train_vec,
   batch_size       = 50, 
   epochs           = 35,
   validation_split = 0.30
)
```

学習履歴の評価
```{r}
print(history)
plot(history)
```


### 精度評価
学習済みモデルによる予測を実施。
```{r}
yhat_keras_class_vec <- 
   predict_classes(object = model_keras, 
                   x = as.matrix(x_test_tbl)) %>% # 分類結果
   as.vector()

yhat_keras_prob_vec  <- 
   predict_proba(object = model_keras, 
                 x = as.matrix(x_test_tbl)) %>% # 確率
   as.vector()

estimates_keras_tbl <- tibble(
   truth      = as.factor(y_test_vec) %>% fct_recode(yes = "1", no = "0"),
   estimate   = as.factor(yhat_keras_class_vec) %>% fct_recode(yes = "1", no = "0"),
   class_prob = yhat_keras_prob_vec
)
estimates_keras_tbl
options(yardstick.event_first = FALSE)
```

精度評価を実施。
```{r}
# 混同行列
estimates_keras_tbl %>% conf_mat(truth, estimate)

# 正解率
estimates_keras_tbl %>% metrics(truth, estimate)

# AUC
estimates_keras_tbl %>% roc_auc(truth, class_prob)

# Precision & Recall
tibble(
   precision = estimates_keras_tbl %>% precision(truth, estimate),
   recall    = estimates_keras_tbl %>% recall(truth, estimate)
)

# F-Statistic
estimates_keras_tbl %>% f_meas(truth, estimate, beta = 1)
```



## 4.結果の解釈
以降は{lime}パッケージを用いた結果の解釈可能性について

```{r}
class(model_keras)

# Setup lime::model_type() function for keras
model_type.keras.models.Sequential <- function(x, ...) {
   "classification"
}

# Setup lime::predict_model() function for keras
predict_model.keras.models.Sequential <- function(x, newdata, type, ...) {
   pred <- predict_proba(object = x, 
                         x = as.matrix(newdata))
   data.frame(Yes = pred, No = 1 - pred)
}

# Test our predict_model() function
predict_model(x = model_keras, newdata = x_test_tbl, type = 'raw') %>%
   tibble::as_tibble()

# Run lime() on training set
explainer <- lime::lime(
   x              = x_train_tbl, 
   model          = model_keras, 
   bin_continuous = FALSE
)

# Run explain() on explainer
explanation <- lime::explain(
   x_test_tbl[1:10, ], 
   explainer    = explainer, 
   n_labels     = 1, 
   n_features   = 4,
   kernel_width = 0.5
)

plot_features(explanation) +
   labs(title = "LIME Feature Importance Visualization",
        subtitle = "Hold Out (Test) Set, First 10 Cases Shown")

plot_explanations(explanation) +
   labs(title = "LIME Feature Importance Heatmap",
        subtitle = "Hold Out (Test) Set, First 10 Cases Shown")
```

{lime}に加え、相関分析による結果も確認する。

```{r}
corrr_analysis <- 
   x_train_tbl %>%
   mutate(Churn = y_train_vec) %>%
   correlate() %>%
   focus(Churn) %>%
   rename(feature = rowname) %>%
   arrange(abs(Churn)) %>%
   mutate(feature = as_factor(feature)) 
corrr_analysis

ggplot(data = corrr_analysis, 
       aes(x = Churn, y = fct_reorder(feature, desc(Churn)))) +
   geom_point() +
   # Positive Correlations - Contribute to churn
   geom_segment(aes(xend = 0, yend = feature), 
                color = palette_light()[[2]], 
                data = corrr_analysis %>% filter(Churn > 0)) +
   geom_point(color = palette_light()[[2]], 
              data = corrr_analysis %>% filter(Churn > 0)) +
   # Negative Correlations - Prevent churn
   geom_segment(aes(xend = 0, yend = feature), 
                color = palette_light()[[1]], 
                data = corrr_analysis %>% filter(Churn < 0)) +
   geom_point(color = palette_light()[[1]], 
              data = corrr_analysis %>% filter(Churn < 0)) +
   # Vertical lines
   geom_vline(xintercept = 0, color = palette_light()[[5]], size = 1, linetype = 2) +
   geom_vline(xintercept = -0.25, color = palette_light()[[5]], size = 1, linetype = 2) +
   geom_vline(xintercept = 0.25, color = palette_light()[[5]], size = 1, linetype = 2) +
   # Aesthetics
   theme_tq() +
   labs(title = "Churn Correlation Analysis",
        subtitle = "Positive Correlations (contribute to churn), Negative Correlations (prevent churn)",
        y = "Feature Importance")
```
