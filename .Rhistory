fit
ice_carat <- fitt %>%
partial(pred.var = "Churn",
pred.fun = pred_wrapper,
train = df_test_baked,
type = "classificatiom")
ice_carat <- fit %>%
partial(pred.var = "Churn",
pred.fun = pred_wrapper,
train = df_test_baked,
type = "classificatiom")
ice_carat <- fit %>%
partial(pred.var = "Churn",
pred.fun = pred_wrapper,
train = df_test_baked,
type = "classification")
rec <- recipe(Churn ~ gender + tenure + MonthlyCharges + TotalCharges,
data = df_train) %>%
# step_log(MonthlyCharges) %>%
# step_log(TotalCharges) %>%
# step_ordinalscore(all_nominal()) %>%
prep(df_train)
df_train_baked <- juice(rec)
df_test_baked <- bake(rec, df_test)
fit <- rand_forest(mode = "classification",
trees = 100,
min_n = 5,
mtry = 2) %>%
set_engine("ranger", num.threads = parallel::detectCores(), seed = 42) %>%
fit(Churn ~ ., data = na.omit(juice(rec)))
pred_wrapper = function(object, newdata) {
return(predict(object, newdata) %>% pull(.pred))
}
fit %>%
vip(method = "permute",  # 変数重要度の計算方法
pred_wrapper = pred_wrapper,
target = df_test_baked %>% pull(TotalCharges),
train = df_test_baked %>% select(-TotalCharges),
reference_class = "Yes",
metric = "auc")
df_train
rec
fit
df_test_baked %>% pull(TotalCharges)
df_test_baked %>% select(-TotalCharges)
fit %>%
vip(method = "permute",  # 変数重要度の計算方法
pred_wrapper = pred_wrapper,
target = df_test_baked %>% pull(Churn),
train = df_test_baked %>% select(-Churn),
reference_class = "Yes",
metric = "auc")
df_test_baked
df_test_baked %>% pull(Churn)
args(vip)
getMethod("vip")
getMethod(vip)
vip()
vip
getMethod("vip")
methods(vip@)
methods(vip)
vip.default
vip:::vip.default
debug(vip)
fit %>%
vip(method = "permute",  # 変数重要度の計算方法
pred_wrapper = pred_wrapper,
target = df_test_baked %>% pull(Churn),
train = df_test_baked %>% select(-Churn),
reference_class = "Yes",
metric = "auc")
vi
vi(fit)
fit <- rand_forest(mode = "classification",
trees = 100,
min_n = 5,
mtry = 2) %>%
set_engine("randomForest", num.threads = parallel::detectCores(), seed = 42) %>%
fit(Churn ~ ., data = na.omit(juice(rec)))
pred_wrapper = function(object, newdata) {
return(predict(object, newdata) %>% pull(.pred))
}
fit %>%
vip(method = "permute",  # 変数重要度の計算方法
pred_wrapper = pred_wrapper,
target = df_test_baked %>% pull(Churn),
train = df_test_baked %>% select(-Churn),
reference_class = "Yes",
metric = "auc")
undebug(vip)
fit <- rand_forest(mode = "classification",
trees = 100,
min_n = 5,
mtry = 2) %>%
set_engine("randomForest", num.threads = parallel::detectCores(), seed = 42) %>%
fit(Churn ~ ., data = na.omit(juice(rec)))
pred_wrapper = function(object, newdata) {
return(predict(object, newdata) %>% pull(.pred))
}
fit %>%
vip(method = "permute",  # 変数重要度の計算方法
pred_wrapper = pred_wrapper,
target = df_test_baked %>% pull(Churn),
train = df_test_baked %>% select(-Churn),
reference_class = "Yes",
metric = "auc")
df_train <- na.omit(training(df_split))
df_test  <- na.omit(testing(df_split))
rec <- recipe(Churn ~ gender + tenure + MonthlyCharges + TotalCharges,
data = df_train) %>%
# step_log(MonthlyCharges) %>%
# step_log(TotalCharges) %>%
# step_ordinalscore(all_nominal()) %>%
prep(df_train)
df_train_baked <- juice(rec)
df_test_baked <- bake(rec, df_test)
fit <- rand_forest(mode = "classification",
trees = 100,
min_n = 5,
mtry = 2) %>%
set_engine("randomForest", num.threads = parallel::detectCores(), seed = 42) %>%
fit(Churn ~ ., data = juice(rec))
pred_wrapper = function(object, newdata) {
return(predict(object, newdata) %>% pull(.pred))
}
fit %>%
vip(method = "permute",  # 変数重要度の計算方法
pred_wrapper = pred_wrapper,
target = df_test_baked %>% pull(Churn),
train = df_test_baked %>% select(-Churn),
reference_class = "Yes",
metric = "auc")
pred_wrapper = function(object, newdata) {
return(predict(object, newdata) %>% pull(Churn))
}
fit %>%
vip(method = "permute",  # 変数重要度の計算方法
pred_wrapper = pred_wrapper,
target = df_test_baked %>% pull(Churn),
train = df_test_baked %>% select(-Churn),
reference_class = "Yes",
metric = "auc")
pred_wrapper = function(object, newdata) {
return(predict(object, newdata) %>% pull("Churn"))
}
fit %>%
vip(method = "permute",  # 変数重要度の計算方法
pred_wrapper = pred_wrapper,
target = df_test_baked %>% pull(Churn),
train = df_test_baked %>% select(-Churn),
reference_class = "Yes",
metric = "auc")
pred_wrapper = function(object, newdata, target) {
return(predict(object, newdata) %>% pull(target))
}
fit %>%
vip(method = "permute",  # 変数重要度の計算方法
pred_wrapper = pred_wrapper,
target = df_test_baked %>% pull(Churn),
train = df_test_baked %>% select(-Churn),
reference_class = "Yes",
metric = "auc")
pred_wrapper = function(object, newdata) {
return(predict(object, newdata) %>% pull(.pred))
}
fit %>%
vip(method = "permute",  # 変数重要度の計算方法
pred_wrapper = pred_wrapper,
target = df_test_baked %>% pull(Churn),
train = df_test_baked %>% select(-Churn),
reference_class = "Yes",
metric = "auc")
# Simulate training data
set.seed(101)  # for reproducibility
trn <- as.data.frame(mlbench::mlbench.friedman1(500))  # ?mlbench.friedman1
install.packages("mlbench")
trn <- as.data.frame(mlbench::mlbench.friedman1(500))  # ?mlbench.friedman1
rfo <- ranger(y ~ ., data = trn, importance = "impurity")
library(ranger)
rfo <- ranger(y ~ ., data = trn, importance = "impurity")
(vi_rfo <- rfo$variable.importance)
barplot(vi_rfo, horiz = TRUE, las = 1)
library(xgboost)  # for fitting GBMs
install.packages("xgboost")
install.packages("xgboost")
library(rpart)    # for fitting CART-like decision trees
# Fit a single regression tree
tree <- rpart(y ~ ., data = trn)
# Fit a GBM
set.seed(102)
bst <- xgboost(
data = data.matrix(subset(trn, select = -y)),
label = trn$y,
objective = "reg:linear",
nrounds = 100,
max_depth = 5,
eta = 0.3,
verbose = 0  # suppress printing
)
library(xgboost)  # for fitting GBMs
bst <- xgboost(
data = data.matrix(subset(trn, select = -y)),
label = trn$y,
objective = "reg:linear",
nrounds = 100,
max_depth = 5,
eta = 0.3,
verbose = 0  # suppress printing
)
p1 <- vip(tree)  # CART-like decision tree
p2 <- vip(rfo, width = 0.5, fill = "green3")   # RF
p3 <- vip(bst, col = "purple2")   # GBM
# Display all three plots side by side
grid.arrange(p1, p2, p3, ncol = 3)
install.packages("pdp")
install.packages("pdp")
install.packages("pdp")
# Load required packages
library(pdp)
# Fit a PPR model (nterms was chosen using the caret package with 5 repeats of
# 5-fold cross-validation)
pp <- ppr(y ~ ., data = trn, nterms = 11)
# PDPs for all 10 features
features <- paste0("x.", 1:10)
pdps <- lapply(features, FUN = function(feature) {
pd <- partial(pp, pred.var = feature)
autoplot(pd) +
ylim(range(trn$y)) +
theme_light()
})
library(tidyverse)
library(tidymodels)
pdps <- lapply(features, FUN = function(feature) {
pd <- partial(pp, pred.var = feature)
autoplot(pd) +
ylim(range(trn$y)) +
theme_light()
})
# Fit a PPR model (nterms was chosen using the caret package with 5 repeats of
# 5-fold cross-validation)
pp <- ppr(y ~ ., data = trn, nterms = 11)
# PDPs for all 10 features
features <- paste0("x.", 1:10)
pdps <- lapply(features, FUN = function(feature) {
pd <- partial(pp, pred.var = feature)
autoplot(pd) +
ylim(range(trn$y)) +
theme_light()
})
partial(pp, pred.var = feature)
pp
features
# PDPs for all 10 features
features <- paste0("x.", 1:10)
pdps <- lapply(features, FUN = function(feature) {
pd <- partial(pp, pred.var = feature)
autoplot(pd) +
ylim(range(trn$y)) +
theme_light()
})
ice_curves <- lapply(features, FUN = function(feature) {
ice <- partial(pp, pred.var = feature, ice = TRUE)
autoplot(ice, alpha = 0.1) +
ylim(range(trn$y)) +
theme_light()
})
grid.arrange(grobs = ice_curves, ncol = 5)
args(partial)
pp
is.function(pp)
str(pp)
ice_curves <- lapply(features, FUN = function(feature) {
ice <- partial(pp$call, pred.var = feature, ice = TRUE)
autoplot(ice, alpha = 0.1) +
ylim(range(trn$y)) +
theme_light()
})
library(randomForest)
data (boston)  # load the boston housing data
set.seed(101)  # for reproducibility
boston.rf <- randomForest(cmedv ~ ., data = boston)
# Using randomForest's partialPlot function
partialPlot(boston.rf, pred.data = boston, x.var = "lstat")
# Using pdp's partial function
head(partial(boston.rf, pred.var = "lstat"))  # returns a data frame
partial(boston.rf, pred.var = "lstat", plot = TRUE, rug = TRUE)
# The partial function allows for multiple predictors
partial(boston.rf, pred.var = c("lstat", "rm"), grid.resolution = 40,
plot = TRUE, chull = TRUE, progress = "text")
# The plotPartial function offers more flexible plotting
pd <- partial(boston.rf, pred.var = c("lstat", "rm"), grid.resolution = 40)
plotPartial(pd, levelplot = FALSE, zlab = "cmedv", drape = TRUE,
colorkey = FALSE, screen = list(z = -20, x = -60))
# The autplot function can be used to produce graphics based on ggplot2
library(ggplot2)
autoplot(pd, contour = TRUE, legend.title = "Partial\ndependence")
ice_curves <- lapply(features, FUN = function(feature) {
ice <- pdp::partial(pp, pred.var = feature, ice = TRUE)
autoplot(ice, alpha = 0.1) +
ylim(range(trn$y)) +
theme_light()
})
grid.arrange(grobs = ice_curves, ncol = 5)
# PDPs for all 10 features
features <- paste0("x.", 1:10)
pdps <- lapply(features, FUN = function(feature) {
pd <- pdp::partial(pp, pred.var = feature)
autoplot(pd) +
ylim(range(trn$y)) +
theme_light()
})
grid.arrange(grobs = pdps, ncol = 5)
3^0
0^2
0^0/5
0^0.5
1^0.5
1^0
0^0.02
1^0.02
100 * (10,000^0.02 - 1)
100 * (10,000^0.02 - 1)
100 * (10000^0.02 - 1)
100 * (1^0.02 - 1)
100 * (10,000^0.02 )
100 * (10000^0.02 )
100 * (1^0.02 - 1)
100 * (0 ^ 0.5 - 1)
100 * (0.5 ^ 0 - 1)
100 * (10^0.02 - 1)
sessionInfo()
library(plotmo)
install.packages("plotmo")
library(glmnet)
library(plotmo)
x <- scale(LifeCycleSavings[, 2:5])
y <- LifeCycleSavings[, 1] - mean(LifeCycleSavings[, 1])
lasso <- glmnet(x, y, family = "gaussian", alpha = 1)
ridge <- glmnet(x, y, family = "gaussian", alpha = 0)
png("glmnet_dive_01_01.png", width = 100, height = 100)
plot_glmnet(lasso, xvar = "lambda", label = TRUE)
dev.off()
png("glmnet_dive_01_01.png", width = 100, height = 100)
plot_glmnet(lasso, xvar = "lambda", label = TRUE)
plot_glmnet(lasso, xvar = "lambda", label = TRUE)
plot_glmnet(lasso, xvar = "lambda", label = TRUE)
png("glmnet_dive_01_01.png", width = 600, height = 400)
plot_glmnet(lasso, xvar = "lambda", label = TRUE)
dev.off()
pwd()
getdi()
getdir()
getwd()
png("./Image/glmnet_dive_01_01.png", width = 600, height = 400)
plot_glmnet(lasso, xvar = "lambda", label = TRUE)
dev.off()
png("./Image/glmnet_dive_01_01.png", width = 600, height = 400)
plot_glmnet(lasso, xvar = "lambda", label = TRUE)
dev.off()
setwd("./Documents/GitHub/R_Snippet/")
png("./Image/glmnet_dive_01_01.png", width = 600, height = 400)
plot_glmnet(lasso, xvar = "lambda", label = TRUE)
dev.off()
png("./Image/glmnet_dive_01_02.png", width = 600, height = 400)
plot_glmnet(ridge, xvar = "lambda", label = TRUE)
dev.off()
plot_glmnet(lasso, xvar = "lambda", label = TRUE)
plot_glmnet(ridge, xvar = "lambda", label = TRUE)
plot_glmnet(lasso, xvar = "lambda", label = TRUE)
plot_glmnet(ridge, xvar = "lambda", label = TRUE)
summary(lasso)
str(lasso)
glmnet
glm
plot_glmnet(lasso, xvar = "lambda", label = TRUE)
ls()
x
head(x)
head(y)
hist(y)
norm(y, y+3)
head(y)
norm(y, y)
norm(y)
norm(y, 1)
norm(y, type = "2")
norm(y, type = "1")
sum(y^2)
sqrt(sum(y^2))
head(x)
X <- as.matrix(1, x)
dim(X)
x
as.matrix(x)
head(as.matrix(x))
X <- as.matrix(cbind(1, x))
head(X)
colnames(X)
colnames(X)[1] <- "Intercept"
beta <- rep(0.5, 5)
my_glmnet <- function(beta, X, y) {
yhat <- X %*% beta
rss <- sqrt(sum((y-yhat)^2))
}
my_lm <- function(beta, X, y) {
yhat <- X %*% beta
rss <- sqrt(sum((y-yhat)^2))
}
calc_rss <- function(beta, X, y) {
yhat <- X %*% beta
rss <- sqrt(sum((y-yhat)^2))
}
optim(beta, calc_rss)
optim(beta, calc_rss, X = X, y = y)
coef(lm(y ~ x))
optim(optim(beta, calc_rss, X = X, y = y)$par, calc_rss, X = X, y = y)
coef(lm(y ~ x))
calc_rss <- function(beta, X, y) {
yhat <- X %*% beta
rss <- sqrt(sum((y-yhat)^2))
return(rss)
}
optim(optim(beta, calc_rss, X = X, y = y)$par, calc_rss, X = X, y = y)
calc_pnl <- function(beta, X, y, lambda, alpha) {
yhat <- X %*% beta
rss <- sqrt(sum((y-yhat)^2))
penal <- rss + lambda * ((1-alpha)/2 * abs(beta) + alpha * sum(beta^2))
return(penal)
}
optim(beta, calc_pnl, X = X, y = y, lambda = 0.5, alpha = 1)
cacl_pne
cacl_pnl(beta, x, y, 0.5, 1)
calc_pnl <- function(beta, X, y, lambda, alpha) {
yhat <- X %*% beta
rss <- sqrt(sum((y-yhat)^2))
penal <- rss + lambda * ((1-alpha)/2 * abs(beta) + alpha * sum(beta^2))
return(penal)
}
cacl_pnl(beta, x, y, 0.5, 1)
calc_pnl(beta, x, y, 0.5, 1)
beta
calc_pnl(beta, X, y, 0.5, 1)
calc_pnl <- function(beta, X, y, lambda, alpha) {
yhat <- X %*% beta
rss <- sqrt(sum((y-yhat)^2))
penal <- rss + lambda * ((1-alpha)/2 * sum(abs(beta)) + alpha * sum(beta^2))
return(penal)
}
optim(beta, calc_pnl, X = X, y = y, lambda = 0.5, alpha = 1)
glmnet(y ~ X, family = "gaussian", alpha = 1, lambda = 0.5)
glmnet(X, y, family = "gaussian", alpha = 1, lambda = 0.5)
coef(glmnet(X, y, family = "gaussian", alpha = 1, lambda = 0.5))
coef(glmnet(X, y, family = "gaussian", alpha = 0, lambda = 0.5))
coef(glmnet(x, y, family = "gaussian", alpha = 0, lambda = 0.5))
coef(glmnet(x, y, family = "gaussian", alpha = 1, lambda = 0.5))
coef(glmnet(x, y, family = "gaussian", alpha = 0, lambda = 0.5))
optim(beta, calc_pnl, X = X, y = y, lambda = 0.5, alpha = 0)
X <- as.matrix(cbind(1, x))
colnames(X)[1] <- "Intercept"
beta <- rep(0.5, 5)
calc_rss <- function(beta, X, y) {
yhat <- X %*% beta
rss <- sqrt(sum((y-yhat)^2))
return(rss)
}
optim(optim(beta, calc_rss, X = X, y = y)$par, calc_rss, X = X, y = y)
calc_pnl <- function(beta, X, y, lambda, alpha) {
yhat <- X %*% beta
rss <- sqrt(sum((y-yhat)^2)) / 2
penal <- rss + lambda * ((1-alpha)/2 * sum(abs(beta)) + alpha * sum(beta^2))
return(penal)
}
optim(beta, calc_pnl, X = X, y = y, lambda = 0.5, alpha = 0)
coef(glmnet(x, y, family = "gaussian", alpha = 0, lambda = 0.5))
(1 + 0.5)^-0.5
(1 + 0.5)^0.5
(2)^0.5
(2)^-0.5
2^-1
3^-1
1.4^-1
lam <- 0.5
sqrt((1 + lam))
-sqrt((1 + lam))
(1+lam)-0.5
(1+lam)^-0.5
(1+lam)^0.5
(1+lam)^0.5 / (1+lam)^0.5
(1+lam)^0.5 * (1+lam)^0.5
lam <- 0.3
(1+lam)^0.5 * (1+lam)^0.5
(1+lam)^0.5 * (1+lam)^-0.5
lam <- 0.5
(1+lam)^0.5 * (1+lam)^-0.5
elnet
glmnet:::elnet
getwd()
download.packages("glmnet", destdir = ".", type = "source")
untar(download.packages("glmnet,
destdir = ".",
type = "source")[,2])
untar(download.packages("glmnet,
destdir = ".",
type = "source")[,2]
untar(download.packages("glmnet,
destdir = ".",
type = "source")[,2])
untar(download.packages("glmnet",
destdir = ".",
type = "source")[,2])
getwd()
